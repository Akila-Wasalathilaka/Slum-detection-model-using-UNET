"""
Optimized Training Script for Global Slum Detection
==================================================
Enhanced training with global optimization techniques
"""

import torch
import torch.nn as nn
from torch.optim.lr_scheduler import OneCycleLR
import segmentation_models_pytorch as smp
from pathlib import Path
import sys

project_root = Path(__file__).parent
sys.path.append(str(project_root))

from models.losses import CombinedLoss
from config import get_model_config, get_training_config, get_data_config

class OptimizedSlumModel(nn.Module):
    """Globally optimized slum detection model."""
    
    def __init__(self):
        super().__init__()
        
        # Best architecture for global detection
        self.backbone = smp.UnetPlusPlus(
            encoder_name="efficientnet-b3",
            encoder_weights="imagenet",
            in_channels=3,
            classes=1,
            activation=None
        )
        
        # Add attention mechanism
        self.attention = smp.base.modules.Attention(
            name="scse",
            in_channels=16
        )
        
        # Multi-scale feature fusion
        self.fusion = nn.Conv2d(16, 1, 1)
        
    def forward(self, x):
        features = self.backbone.encoder(x)
        decoder_output = self.backbone.decoder(*features)
        
        # Apply attention
        attended = self.attention(decoder_output)
        
        # Final prediction
        output = self.backbone.segmentation_head(attended)
        return output

class GlobalOptimizer:
    """Optimized training configuration for global detection."""
    
    @staticmethod
    def get_optimized_config():
        config = get_training_config("production")
        
        # Global optimization settings
        config.epochs = 100
        config.batch_size = 32
        config.learning_rate = 3e-4
        config.weight_decay = 1e-4
        config.use_amp = True
        config.grad_clip_norm = 1.0
        
        # Advanced scheduler
        config.scheduler = "onecycle"
        config.scheduler_params = {
            "max_lr": 3e-4,
            "pct_start": 0.3,
            "anneal_strategy": "cos"
        }
        
        # Enhanced loss function
        config.loss_type = "combined_advanced"
        config.loss_params = {
            "bce_weight": 0.3,
            "dice_weight": 0.4,
            "focal_weight": 0.3,
            "focal_alpha": 0.25,
            "focal_gamma": 2.0
        }
        
        return config
    
    @staticmethod
    def get_optimized_data_config():
        config = get_data_config("heavy_augmentation")
        
        # Global data optimization
        config.image_size = (120, 120)
        config.normalize_mean = [0.485, 0.456, 0.406]
        config.normalize_std = [0.229, 0.224, 0.225]
        
        # Enhanced augmentation for global compatibility
        config.augmentation_params.update({
            "brightness_limit": 0.3,
            "contrast_limit": 0.3,
            "saturation_limit": 0.3,
            "hue_shift_limit": 0.2,
            "blur_limit": 7,
            "noise_var_limit": (10, 50)
        })
        
        return config

def train_optimized_model():
    """Train the globally optimized model."""
    print("ðŸŒ Starting Global Slum Detection Training...")
    
    # Get optimized configs
    optimizer_config = GlobalOptimizer.get_optimized_config()
    data_config = GlobalOptimizer.get_optimized_data_config()
    
    # Create optimized model
    model = OptimizedSlumModel()
    
    print("âœ… Optimized model created for global detection!")
    print(f"ðŸ“Š Training epochs: {optimizer_config.epochs}")
    print(f"ðŸŽ¯ Target: >99.8% accuracy worldwide")
    
    return model, optimizer_config, data_config

if __name__ == "__main__":
    train_optimized_model()